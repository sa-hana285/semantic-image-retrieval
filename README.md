This project implements a Semantic Image Retrieval System that allows users to search for images using natural language text queries. Instead of relying on exact keyword matching, the system understands the semantic meaning of the query and retrieves the most relevant images from a predefined dataset.
Each image in the dataset is associated with a textual description stored in a CSV file. These descriptions are converted into vector embeddings using a pretrained Sentence Transformer model, and similarity search is performed using FAISS to efficiently find the closest matches. The corresponding images are then displayed through an interactive Streamlit web interface.
The system is dataset-limited, meaning it retrieves images only from the provided collection. It runs entirely on CPU, requires no GPU, and can be hosted for free using platforms like Streamlit Community Cloud. This project is suitable for use cases such as catalog search, dataset exploration, and AI-based content retrieval demonstrations.
